{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831a7ab5",
   "metadata": {},
   "source": [
    "# Create Multi-AI Agent to Research and Write an Article\n",
    "\n",
    "\n",
    "Learn about Agents, Tasks and organize agents to work sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6972966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.3 (main, Apr 27 2024, 19:00:21) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "# To install crewAI, you need to have Python >=3.10 and <=3.13 installed on your system:\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ecffc",
   "metadata": {},
   "source": [
    "### Step 01. Intalling dependencies\n",
    "\n",
    "Installing crewAi library and crewAI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4c318c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai\n",
      "  Downloading crewai-0.30.11-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.4 (from crewai)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from crewai)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting embedchain<0.2.0,>=0.1.98 (from crewai)\n",
      "  Downloading embedchain-0.1.103-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting instructor<0.6.0,>=0.5.2 (from crewai)\n",
      "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain<0.2.0,>=0.1.10 (from crewai)\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
      "  Downloading openai-1.30.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.4.2 (from crewai)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv<2.0.0,>=1.0.0 (from crewai)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting regex<2024.0.0,>=2023.12.25 (from crewai)\n",
      "  Downloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in ./myenv/lib/python3.12/site-packages (from embedchain<0.2.0,>=0.1.98->crewai) (4.12.3)\n",
      "Collecting chromadb<0.6.0,>=0.5.0 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_aiplatform-1.51.0-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading gptcache-0.1.43-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-openai<0.0.6,>=0.0.5 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=2.0.27 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading tiktoken-0.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.3 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typer<0.10.0,>=0.9.0 (from instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./myenv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.10->crewai) (6.0.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading langsmith-0.1.59-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in ./myenv/lib/python3.12/site-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.31.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./myenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.13.3->crewai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./myenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./myenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.13.3->crewai)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions<5,>=4.7 (from openai<2.0.0,>=1.13.3->crewai)\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3.0.0,>=2.4.2->crewai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3.0.0,>=2.4.2->crewai)\n",
      "  Downloading pydantic_core-2.18.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./myenv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./myenv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain<0.2.0,>=0.1.98->crewai) (2.5)\n",
      "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading onnxruntime-1.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in ./myenv/lib/python3.12/site-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpcio-1.63.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading mmh3-4.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading orjson-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in ./myenv/lib/python3.12/site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai) (24.0)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_bigquery-3.23.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading shapely-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (0.14.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading zipp-3.18.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packaging>=14.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in ./myenv/lib/python3.12/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (2.2.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.12/site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai) (2.18.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3.0.0,>=2.0.27->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in ./myenv/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (3.1.4)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading ujson-5.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading google-crc32c-1.5.0.tar.gz (12 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in ./myenv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai) (2.4)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./myenv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting setuptools>=16.0 (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading httptools-0.6.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading uvloop-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading watchfiles-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading websockets-12.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./myenv/lib/python3.12/site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai) (2.1.5)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is looking at multiple versions of fastapi-cli to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastapi_cli-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading fastapi_cli-0.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading crewai-0.30.11-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading embedchain-0.1.103-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
      "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m293.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_aiplatform-1.51.0-py2.py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
      "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.59-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Downloading SQLAlchemy-2.0.30-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tiktoken-0.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading google_cloud_bigquery-3.23.0-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.1/237.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.7/333.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (625 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m625.7/625.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.63.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading orjson-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.18.2-py3-none-any.whl (8.3 kB)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading httptools-0.6.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.7/344.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading websockets-12.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib, pypika, google-crc32c\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.3-cp312-cp312-linux_x86_64.whl size=2351099 sha256=fad8d0167ed7c710b4be3bb4ac5bfd22a5b4a1fed49ca571249e6442207717ce\n",
      "  Stored in directory: /home/akj/.cache/pip/wheels/6d/14/b5/68c4f2e056600c0348a94efba92dc975686ab72b714e0ca3d6\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=73cbfd0ba60a3a86645769a02d8b3c0fafa91e4f5310ccba1c268d9d615282bd\n",
      "  Stored in directory: /home/akj/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "  Building wheel for google-crc32c (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-crc32c: filename=google_crc32c-1.5.0-py3-none-any.whl size=13026 sha256=2bcefad0a75325bf4a40957f83faaad369b4c1cdb37d5114b36863ef9c7658a2\n",
      "  Stored in directory: /home/akj/.cache/pip/wheels/40/b9/2e/089df51c5e6f7cda282c650457a1d9a7a55bf6386d8de8bf3d\n",
      "Successfully built chroma-hnswlib pypika google-crc32c\n",
      "Installing collected packages: schema, pypika, mpmath, monotonic, mmh3, flatbuffers, appdirs, zipp, wrapt, websockets, uvloop, typing-extensions, tqdm, tenacity, sympy, setuptools, regex, python-dotenv, pysbd, pyproject_hooks, pypdf, pyasn1, protobuf, packaging, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, numpy, mypy-extensions, multidict, mdurl, Mako, jsonpatch, importlib-resources, humanfriendly, httptools, grpcio, greenlet, google-crc32c, fsspec, frozenlist, filelock, docstring-parser, distro, click, cachetools, bcrypt, backoff, asgiref, annotated-types, yarl, watchfiles, uvicorn, typing-inspect, typer, tiktoken, starlette, sqlalchemy, shapely, rsa, requests-oauthlib, pydantic-core, pyasn1-modules, proto-plus, posthog, opentelemetry-proto, marshmallow, markdown-it-py, importlib-metadata, huggingface-hub, gptcache, googleapis-common-protos, google-resumable-media, deprecated, coloredlogs, chroma-hnswlib, build, aiosignal, tokenizers, rich, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, grpcio-status, google-auth, dataclasses-json, alembic, aiohttp, opentelemetry-sdk, opentelemetry-instrumentation, openai, langsmith, kubernetes, grpc-google-iam-v1, google-api-core, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-core, instructor, google-cloud-core, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-openai, langchain-community, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, langchain, google-cloud-aiplatform, chromadb, embedchain, crewai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed Mako-1.3.5 aiohttp-3.9.5 aiosignal-1.3.1 alembic-1.13.1 annotated-types-0.6.0 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.5.0 click-8.1.7 coloredlogs-15.0.1 crewai-0.30.11 dataclasses-json-0.6.6 deprecated-1.2.14 distro-1.9.0 docstring-parser-0.15 embedchain-0.1.103 fastapi-0.110.3 filelock-3.14.0 flatbuffers-24.3.25 frozenlist-1.4.1 fsspec-2024.5.0 google-api-core-2.19.0 google-auth-2.29.0 google-cloud-aiplatform-1.51.0 google-cloud-bigquery-3.23.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.16.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 gptcache-0.1.43 greenlet-3.0.3 grpc-google-iam-v1-0.13.0 grpcio-1.63.0 grpcio-status-1.62.2 httptools-0.6.1 huggingface-hub-0.23.0 humanfriendly-10.0 importlib-metadata-7.0.0 importlib-resources-6.4.0 instructor-0.5.2 jsonpatch-1.33 kubernetes-29.0.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-openai-0.0.5 langchain-text-splitters-0.0.2 langsmith-0.1.59 markdown-it-py-3.0.0 marshmallow-3.21.2 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.18.0 openai-1.30.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.3 packaging-23.2 posthog-3.5.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.7.1 pydantic-core-2.18.2 pypdf-4.2.0 pypika-0.48.9 pyproject_hooks-1.1.0 pysbd-0.3.4 python-dotenv-1.0.1 regex-2023.12.25 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 schema-0.7.7 setuptools-69.5.1 shapely-2.0.4 sqlalchemy-2.0.30 starlette-0.37.2 sympy-1.12 tenacity-8.3.0 tiktoken-0.5.2 tokenizers-0.19.1 tqdm-4.66.4 typer-0.9.4 typing-extensions-4.11.0 typing-inspect-0.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0 wrapt-1.16.0 yarl-1.9.4 zipp-3.18.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17371042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d08eb7",
   "metadata": {},
   "source": [
    "### Step 02. Importing Libraries\n",
    "\n",
    "Installing crewAi library and crewAI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07001d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c3e093",
   "metadata": {},
   "source": [
    "For LLM agents, we will be using OpenAI's gpt-3.5-turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e2a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aba3e2",
   "metadata": {},
   "source": [
    "### Step 03. Creating Agents\n",
    "\n",
    "Create instance of the Agent class with the desired properties, `role`, `goal` and `backstory`\n",
    "\n",
    "- `role`: agent's function within the crew\n",
    "- `goal`: agent's objective. Guides agent's decision making process\n",
    "- `backstory`: provides context to agent's role and goal. Helps in interation and collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db71ea9",
   "metadata": {},
   "source": [
    "### Agent: Planner\n",
    "\n",
    "**Note**: The benefit of using _multiple strings_ :\n",
    "```Python\n",
    "varname = \"line 1 of text\"\n",
    "          \"line 2 of text\"\n",
    "```\n",
    "\n",
    "versus the _triple quote docstring_:\n",
    "```Python\n",
    "varname = \"\"\"line 1 of text\n",
    "             line 2 of text\n",
    "          \"\"\"\n",
    "```\n",
    "is that it can avoid adding those whitespaces and newline characters, making it better formatted to be passed to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14381472",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Agent(\n",
    "    role=\"Content Planner\",\n",
    "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
    "    backstory=\"You're working on planning a blog article \"\n",
    "              \"about the topic: {topic}.\"\n",
    "              \"You collect information that helps the \"\n",
    "              \"audience learn something \"\n",
    "              \"and make informed decisions. \"\n",
    "              \"Your work is the basis for \"\n",
    "              \"the Content Writer to write an article on this topic\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9c68d",
   "metadata": {},
   "source": [
    "### Agent: Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9475c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role=\"Content Writer\",\n",
    "    goal=\"Write insightful and factually accurate \"\n",
    "         \"opinion piece about the topic: {topic}\",\n",
    "    backstory=\"You're working on a writing \"\n",
    "              \"a new opinion piece about the topic: {topic}. \"\n",
    "              \"You base your writing on the work of \"\n",
    "              \"the Content Planner, who provides an outline \"\n",
    "              \"and relevant context about the topic. \"\n",
    "              \"You follow the main objectives and \"\n",
    "              \"direction of the outline, \"\n",
    "              \"as provide by the Content Planner. \"\n",
    "              \"You also provide objective and impartial insights \"\n",
    "              \"and back them up with information \"\n",
    "              \"provide by the Content Planner. \"\n",
    "              \"You acknowledge in your opinion piece \"\n",
    "              \"when your statements are opinions \"\n",
    "              \"as opposed to objective statements.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409a1fd",
   "metadata": {},
   "source": [
    "### Agent: Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036b60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role=\"Editor\",\n",
    "    goal=\"Edit a given blog post to align with \"\n",
    "         \"the writing style of the organization. \",\n",
    "    backstory=\"You are an editor who receives a blog post \"\n",
    "              \"from the Content Writer. \"\n",
    "              \"Your goal is to review the blog post \"\n",
    "              \"to ensure that it follows journalistic best practices,\"\n",
    "              \"provides balanced viewpoints \"\n",
    "              \"when providing opinions or assertions, \"\n",
    "              \"and also avoids major controversial topics \"\n",
    "              \"or opinions when possible.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13781b",
   "metadata": {},
   "source": [
    "### Step 04. Define the Tasks\n",
    "\n",
    "Tasks are **specific assignments**, completed by agents. \n",
    "They **provide all necessary details for execution**, such as a `description`, `expected_output` , `agent` responsible, tools, etc.\n",
    "\n",
    "- `description`: Tells about what task entails\n",
    "- `expected_output`: Tells about what task output should look like\n",
    "- `agent`: Agent responsible for the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a678a1f",
   "metadata": {},
   "source": [
    "### Task: Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa44c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Prioritize the latest trends, key players, \"\n",
    "            \"and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering \"\n",
    "            \"their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including \"\n",
    "            \"an introduction, key points, and a call to action.\\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive content plan document \"\n",
    "        \"with an outline, audience analysis, \"\n",
    "        \"SEO keywords, and resources.\",\n",
    "    agent=planner,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe3831",
   "metadata": {},
   "source": [
    "### Task: Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373d3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description=(\n",
    "        \"1. Use the content plan to craft a compelling \"\n",
    "            \"blog post on {topic}.\\n\"\n",
    "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
    "        \"3. Sections/Subtitles are properly named \"\n",
    "            \"in an engaging manner.\\n\"\n",
    "        \"4. Ensure the post is structured with an \"\n",
    "            \"engaging introduction, insightful body, \"\n",
    "            \"and a summarizing conclusion.\\n\"\n",
    "        \"5. Proofread for grammatical errors and \"\n",
    "            \"alignment with the brand's voice.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A well-written blog post \"\n",
    "        \"in markdown format, ready for publication, \"\n",
    "        \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5b08d",
   "metadata": {},
   "source": [
    "### Task: Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d9f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description=(\"Proofread the given blog post for \"\n",
    "                 \"grammatical errors and \"\n",
    "                 \"alignment with the brand's voice.\"),\n",
    "    expected_output=\"A well-written blog post in markdown format, \"\n",
    "                    \"ready for publication, \"\n",
    "                    \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=editor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6a3b1",
   "metadata": {},
   "source": [
    "### Step 05. Forming the crew\n",
    "\n",
    "Crew is **group of AI agents**, collaborating to perform set of tasks.\n",
    "\n",
    "\n",
    "- `tasks`: list of tasks\n",
    "- `agents`: list of agents\n",
    "- `process (optional)`: work flow (e.g., sequential, hierarchical) default : sequential \n",
    "- `verbose=2` allows you to see all the logs of the execution. \n",
    "\n",
    "\n",
    "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f391def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    tasks=[plan, write, edit],\n",
    "    agents=[planner, writer, editor],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea102b6",
   "metadata": {},
   "source": [
    "### Step 06.  Kick It Off\n",
    "\n",
    "Pass in a topic of your choice and see what the agents come up with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d787c0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Planner\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can now give a great answer.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence:\n",
      "\n",
      "- Trends: Machine learning, Natural Language Processing(NLP), AI in healthcare, AI in cybersecurity, AI in e-commerce, and AI in logistics.\n",
      "- Key players: Google, Apple, Microsoft, Amazon, IBM, and Facebook.\n",
      "- Noteworthy news: \n",
      "   - Google's New AI Model Mimics Human Speech\n",
      "   - IBM's AI successfully debates with humans\n",
      "   - Apple's introduction of AI in the latest iPhone models\n",
      "   - Amazon's AI-powered Alexa Echo\n",
      "   - Microsoft's AI for accessibility initiative\n",
      "   - Facebook's AI preventing hate speech.\n",
      "\n",
      "2. Identify the target audience:\n",
      "\n",
      "- Tech enthusiasts who want to stay updated with the latest AI trends\n",
      "- Business owners who are considering implementing AI in their operations\n",
      "- Students studying computer science or related fields\n",
      "- Professionals working in IT, data science, or related fields.\n",
      "\n",
      "Pain Points:\n",
      "- Lack of understanding of AI and its capabilities\n",
      "- Difficulty in keeping up with fast-paced AI developments\n",
      "- Uncertainty about the impacts of AI on jobs and privacy.\n",
      "\n",
      "3. Content Outline:\n",
      "\n",
      "Introduction:\n",
      "- Brief overview of AI\n",
      "- Importance of AI in today's world\n",
      "\n",
      "Key Points:\n",
      "- Latest trends in AI and their implications\n",
      "   - Detailed analysis of each trend with examples from key players\n",
      "- How AI is changing various industries\n",
      "   - Case studies of successful AI implementation in different sectors\n",
      "- The future of AI: Opportunities and challenges\n",
      "   - In-depth discussion on AI's potential impacts on jobs and privacy\n",
      "\n",
      "Call to Action:\n",
      "- Encourage readers to stay informed about AI developments\n",
      "- Invite readers to share their views on AI's impacts on their lives.\n",
      "\n",
      "4. SEO Keywords: Artificial Intelligence, AI trends, machine learning, natural language processing, AI in healthcare, AI in cybersecurity, AI in e-commerce, AI in logistics, Google AI, Apple AI, Microsoft AI, IBM AI, Amazon AI, Facebook AI.\n",
      "\n",
      "5. Relevant Data/Sources:\n",
      "- Statista for latest AI market statistics\n",
      "- Company websites and press releases for updates on their AI projects\n",
      "- AI research papers from Google Scholar for technical details\n",
      "- News articles from TechCrunch, Wired, and The Verge for latest AI news.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [Content Planner] Task output: 1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence:\n",
      "\n",
      "- Trends: Machine learning, Natural Language Processing(NLP), AI in healthcare, AI in cybersecurity, AI in e-commerce, and AI in logistics.\n",
      "- Key players: Google, Apple, Microsoft, Amazon, IBM, and Facebook.\n",
      "- Noteworthy news: \n",
      "   - Google's New AI Model Mimics Human Speech\n",
      "   - IBM's AI successfully debates with humans\n",
      "   - Apple's introduction of AI in the latest iPhone models\n",
      "   - Amazon's AI-powered Alexa Echo\n",
      "   - Microsoft's AI for accessibility initiative\n",
      "   - Facebook's AI preventing hate speech.\n",
      "\n",
      "2. Identify the target audience:\n",
      "\n",
      "- Tech enthusiasts who want to stay updated with the latest AI trends\n",
      "- Business owners who are considering implementing AI in their operations\n",
      "- Students studying computer science or related fields\n",
      "- Professionals working in IT, data science, or related fields.\n",
      "\n",
      "Pain Points:\n",
      "- Lack of understanding of AI and its capabilities\n",
      "- Difficulty in keeping up with fast-paced AI developments\n",
      "- Uncertainty about the impacts of AI on jobs and privacy.\n",
      "\n",
      "3. Content Outline:\n",
      "\n",
      "Introduction:\n",
      "- Brief overview of AI\n",
      "- Importance of AI in today's world\n",
      "\n",
      "Key Points:\n",
      "- Latest trends in AI and their implications\n",
      "   - Detailed analysis of each trend with examples from key players\n",
      "- How AI is changing various industries\n",
      "   - Case studies of successful AI implementation in different sectors\n",
      "- The future of AI: Opportunities and challenges\n",
      "   - In-depth discussion on AI's potential impacts on jobs and privacy\n",
      "\n",
      "Call to Action:\n",
      "- Encourage readers to stay informed about AI developments\n",
      "- Invite readers to share their views on AI's impacts on their lives.\n",
      "\n",
      "4. SEO Keywords: Artificial Intelligence, AI trends, machine learning, natural language processing, AI in healthcare, AI in cybersecurity, AI in e-commerce, AI in logistics, Google AI, Apple AI, Microsoft AI, IBM AI, Amazon AI, Facebook AI.\n",
      "\n",
      "5. Relevant Data/Sources:\n",
      "- Statista for latest AI market statistics\n",
      "- Company websites and press releases for updates on their AI projects\n",
      "- AI research papers from Google Scholar for technical details\n",
      "- News articles from TechCrunch, Wired, and The Verge for latest AI news.\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Writer\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Use the content plan to craft a compelling blog post on Artificial Intelligence.\n",
      "2. Incorporate SEO keywords naturally.\n",
      "3. Sections/Subtitles are properly named in an engaging manner.\n",
      "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "# Decoding Artificial Intelligence: A Modern Era Perspective\n",
      "\n",
      "Artificial Intelligence (AI), once a concept confined to sci-fi novels and futuristic movies, is now an inextricable part of our everyday life. From voice assistants like Alexa to personalized recommendations on Amazon, AI has made significant strides. Its importance in today's world cannot be overstated as industries across the spectrum leverage AI for efficiency, precision, and innovation.\n",
      "\n",
      "## Riding the Wave of AI Trends\n",
      "\n",
      "The AI landscape is evolving at a breakneck pace. Machine learning and Natural Language Processing (NLP) are at the forefront, driving innovations in healthcare, cybersecurity, e-commerce, and logistics. *[Google's latest AI model](https://blog.google/technology/ai/latest-advancements-speech-recognition/)*, for instance, has pushed the boundaries of human speech mimicry, while *[IBM's AI](https://newsroom.ibm.com/2018-06-18-IBM-Debuts-Project-Debater-AI-System-That-Masters-Debate)* has successfully held its ground in debates against humans—signifying AI's incredible progression.\n",
      "\n",
      "## AI: Changing the Game Across Industries\n",
      "\n",
      "AI's transformative potential is being recognized and harnessed by key players like Google, Apple, Microsoft, Amazon, IBM, and Facebook. Take Apple's latest iPhone models, for example, which leverage AI for enhanced user experience. Or Amazon's AI-powered Alexa Echo that has revolutionized home automation. AI's proliferation extends to sectors such as healthcare—aiding in disease diagnosis and treatment, and logistics—optimizing supply chain and delivery processes.\n",
      "\n",
      "## The Future of AI: A Double-Edged Sword?\n",
      "\n",
      "As AI continues to advance, it brings forth opportunities and challenges. On the one hand, AI is set to create new jobs and boost productivity. On the other hand, it raises valid concerns over job displacement and privacy breaches. For instance, *[Microsoft's AI for accessibility](https://blogs.microsoft.com/accessibility/category/ai-for-accessibility/)* initiative is empowering people with disabilities, but Facebook's use of AI to prevent hate speech has raised questions about surveillance and censorship.\n",
      "\n",
      "In this dynamic AI landscape, staying informed is crucial. From tech enthusiasts and business owners to students and IT professionals, understanding AI and its capabilities can equip us to harness its benefits and navigate its challenges. We invite you to share your views on AI's impacts on your life and continue this conversation.\n",
      "\n",
      "_*Sources:_ [Statista](https://www.statista.com/statistics/607716/worldwide-artificial-intelligence-market-revenues/), [Google AI Blog](https://blog.google/technology/ai/), [IBM Newsroom](https://newsroom.ibm.com/), [Apple](https://www.apple.com/iphone/), [Amazon](https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/b?ie=UTF8&node=9818047011), [Microsoft AI](https://www.microsoft.com/en-us/ai/ai-for-accessibility), [Facebook AI](https://ai.facebook.com/), [TechCrunch](https://techcrunch.com/), [Wired](https://www.wired.com/), [The Verge](https://www.theverge.com/).*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [Content Writer] Task output: # Decoding Artificial Intelligence: A Modern Era Perspective\n",
      "\n",
      "Artificial Intelligence (AI), once a concept confined to sci-fi novels and futuristic movies, is now an inextricable part of our everyday life. From voice assistants like Alexa to personalized recommendations on Amazon, AI has made significant strides. Its importance in today's world cannot be overstated as industries across the spectrum leverage AI for efficiency, precision, and innovation.\n",
      "\n",
      "## Riding the Wave of AI Trends\n",
      "\n",
      "The AI landscape is evolving at a breakneck pace. Machine learning and Natural Language Processing (NLP) are at the forefront, driving innovations in healthcare, cybersecurity, e-commerce, and logistics. *[Google's latest AI model](https://blog.google/technology/ai/latest-advancements-speech-recognition/)*, for instance, has pushed the boundaries of human speech mimicry, while *[IBM's AI](https://newsroom.ibm.com/2018-06-18-IBM-Debuts-Project-Debater-AI-System-That-Masters-Debate)* has successfully held its ground in debates against humans—signifying AI's incredible progression.\n",
      "\n",
      "## AI: Changing the Game Across Industries\n",
      "\n",
      "AI's transformative potential is being recognized and harnessed by key players like Google, Apple, Microsoft, Amazon, IBM, and Facebook. Take Apple's latest iPhone models, for example, which leverage AI for enhanced user experience. Or Amazon's AI-powered Alexa Echo that has revolutionized home automation. AI's proliferation extends to sectors such as healthcare—aiding in disease diagnosis and treatment, and logistics—optimizing supply chain and delivery processes.\n",
      "\n",
      "## The Future of AI: A Double-Edged Sword?\n",
      "\n",
      "As AI continues to advance, it brings forth opportunities and challenges. On the one hand, AI is set to create new jobs and boost productivity. On the other hand, it raises valid concerns over job displacement and privacy breaches. For instance, *[Microsoft's AI for accessibility](https://blogs.microsoft.com/accessibility/category/ai-for-accessibility/)* initiative is empowering people with disabilities, but Facebook's use of AI to prevent hate speech has raised questions about surveillance and censorship.\n",
      "\n",
      "In this dynamic AI landscape, staying informed is crucial. From tech enthusiasts and business owners to students and IT professionals, understanding AI and its capabilities can equip us to harness its benefits and navigate its challenges. We invite you to share your views on AI's impacts on your life and continue this conversation.\n",
      "\n",
      "_*Sources:_ [Statista](https://www.statista.com/statistics/607716/worldwide-artificial-intelligence-market-revenues/), [Google AI Blog](https://blog.google/technology/ai/), [IBM Newsroom](https://newsroom.ibm.com/), [Apple](https://www.apple.com/iphone/), [Amazon](https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/b?ie=UTF8&node=9818047011), [Microsoft AI](https://www.microsoft.com/en-us/ai/ai-for-accessibility), [Facebook AI](https://ai.facebook.com/), [TechCrunch](https://techcrunch.com/), [Wired](https://www.wired.com/), [The Verge](https://www.theverge.com/).*\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Editor\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: Proofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe blog post is well-written, but there are a few areas where the tone can be made consistent with our brand's voice. Additionally, the piece can be made more balanced by including viewpoints from independent experts or studies to support the claims made.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "# Decoding Artificial Intelligence: A Modern Era Perspective\n",
      "\n",
      "Artificial Intelligence (AI), once a thought only found in science fiction novels and futuristic cinema, has seamlessly integrated into our daily experiences. From voice assistants like Alexa to personalized recommendations on Amazon, AI's presence is felt more than ever. There's no denying its significance in today's world, as countless industries utilize AI to improve efficiency, precision, and innovation.\n",
      "\n",
      "## Catching the AI Wave: Current Trends\n",
      "\n",
      "The world of AI is advancing at an astounding pace, with Machine Learning and Natural Language Processing (NLP) leading the charge. These technologies are propelling innovations across a variety of sectors including healthcare, cybersecurity, e-commerce, and logistics. Consider *[Google's latest AI model](https://blog.google/technology/ai/latest-advancements-speech-recognition/)* that pushes the limits of human speech imitation, while *[IBM's AI](https://newsroom.ibm.com/2018-06-18-IBM-Debuts-Project-Debater-AI-System-That-Masters-Debate)* has impressively held its own in debates against humans—both examples showcasing the remarkable progress of AI.\n",
      "\n",
      "## AI: A Game Changer Across Industries\n",
      "\n",
      "The transformative potential of AI is being acknowledged and utilized by industry giants like Google, Apple, Microsoft, Amazon, IBM, and Facebook. For instance, Apple's latest iPhone models leverage AI to enhance the user experience, while Amazon's AI-powered Alexa Echo offers a new dimension to home automation. The influence of AI is also witnessed in sectors like healthcare—assisting in disease diagnosis and treatment, and logistics—improving supply chain and delivery processes.\n",
      "\n",
      "## The Future of AI: A Double-Edged Sword?\n",
      "\n",
      "As AI continues to evolve, it presents both opportunities and challenges. On the upside, AI is predicted to generate new jobs and enhance productivity. However, it also brings to light concerns over job displacement and privacy violations. For example, *[Microsoft's AI for accessibility](https://blogs.microsoft.com/accessibility/category/ai-for-accessibility/)* initiative empowers people with disabilities. Conversely, Facebook's use of AI to mitigate hate speech has sparked controversy over surveillance and censorship.\n",
      "\n",
      "In this ever-changing AI landscape, staying informed is paramount. Whether you're a tech enthusiast, business owner, student, or IT professional, understanding AI and its capabilities will better equip us to leverage its benefits and navigate its potential pitfalls. We welcome your thoughts on AI's influence on your life and encourage you to continue this conversation.\n",
      "\n",
      "_*Sources:_ [Statista](https://www.statista.com/statistics/607716/worldwide-artificial-intelligence-market-revenues/), [Google AI Blog](https://blog.google/technology/ai/), [IBM Newsroom](https://newsroom.ibm.com/), [Apple](https://www.apple.com/iphone/), [Amazon](https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/b?ie=UTF8&node=9818047011), [Microsoft AI](https://www.microsoft.com/en-us/ai/ai-for-accessibility), [Facebook AI](https://ai.facebook.com/), [TechCrunch](https://techcrunch.com/), [Wired](https://www.wired.com/), [The Verge](https://www.theverge.com/).*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [Editor] Task output: # Decoding Artificial Intelligence: A Modern Era Perspective\n",
      "\n",
      "Artificial Intelligence (AI), once a thought only found in science fiction novels and futuristic cinema, has seamlessly integrated into our daily experiences. From voice assistants like Alexa to personalized recommendations on Amazon, AI's presence is felt more than ever. There's no denying its significance in today's world, as countless industries utilize AI to improve efficiency, precision, and innovation.\n",
      "\n",
      "## Catching the AI Wave: Current Trends\n",
      "\n",
      "The world of AI is advancing at an astounding pace, with Machine Learning and Natural Language Processing (NLP) leading the charge. These technologies are propelling innovations across a variety of sectors including healthcare, cybersecurity, e-commerce, and logistics. Consider *[Google's latest AI model](https://blog.google/technology/ai/latest-advancements-speech-recognition/)* that pushes the limits of human speech imitation, while *[IBM's AI](https://newsroom.ibm.com/2018-06-18-IBM-Debuts-Project-Debater-AI-System-That-Masters-Debate)* has impressively held its own in debates against humans—both examples showcasing the remarkable progress of AI.\n",
      "\n",
      "## AI: A Game Changer Across Industries\n",
      "\n",
      "The transformative potential of AI is being acknowledged and utilized by industry giants like Google, Apple, Microsoft, Amazon, IBM, and Facebook. For instance, Apple's latest iPhone models leverage AI to enhance the user experience, while Amazon's AI-powered Alexa Echo offers a new dimension to home automation. The influence of AI is also witnessed in sectors like healthcare—assisting in disease diagnosis and treatment, and logistics—improving supply chain and delivery processes.\n",
      "\n",
      "## The Future of AI: A Double-Edged Sword?\n",
      "\n",
      "As AI continues to evolve, it presents both opportunities and challenges. On the upside, AI is predicted to generate new jobs and enhance productivity. However, it also brings to light concerns over job displacement and privacy violations. For example, *[Microsoft's AI for accessibility](https://blogs.microsoft.com/accessibility/category/ai-for-accessibility/)* initiative empowers people with disabilities. Conversely, Facebook's use of AI to mitigate hate speech has sparked controversy over surveillance and censorship.\n",
      "\n",
      "In this ever-changing AI landscape, staying informed is paramount. Whether you're a tech enthusiast, business owner, student, or IT professional, understanding AI and its capabilities will better equip us to leverage its benefits and navigate its potential pitfalls. We welcome your thoughts on AI's influence on your life and encourage you to continue this conversation.\n",
      "\n",
      "_*Sources:_ [Statista](https://www.statista.com/statistics/607716/worldwide-artificial-intelligence-market-revenues/), [Google AI Blog](https://blog.google/technology/ai/), [IBM Newsroom](https://newsroom.ibm.com/), [Apple](https://www.apple.com/iphone/), [Amazon](https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/b?ie=UTF8&node=9818047011), [Microsoft AI](https://www.microsoft.com/en-us/ai/ai-for-accessibility), [Facebook AI](https://ai.facebook.com/), [TechCrunch](https://techcrunch.com/), [Wired](https://www.wired.com/), [The Verge](https://www.theverge.com/).*\n",
      "\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "topic = \"Artificial Intelligence\"\n",
    "result = crew.kickoff(inputs={\"topic\": topic})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb540b",
   "metadata": {},
   "source": [
    "To display the result as markdown in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ec1e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Decoding Artificial Intelligence: A Modern Era Perspective\n",
       "\n",
       "Artificial Intelligence (AI), once a thought only found in science fiction novels and futuristic cinema, has seamlessly integrated into our daily experiences. From voice assistants like Alexa to personalized recommendations on Amazon, AI's presence is felt more than ever. There's no denying its significance in today's world, as countless industries utilize AI to improve efficiency, precision, and innovation.\n",
       "\n",
       "## Catching the AI Wave: Current Trends\n",
       "\n",
       "The world of AI is advancing at an astounding pace, with Machine Learning and Natural Language Processing (NLP) leading the charge. These technologies are propelling innovations across a variety of sectors including healthcare, cybersecurity, e-commerce, and logistics. Consider *[Google's latest AI model](https://blog.google/technology/ai/latest-advancements-speech-recognition/)* that pushes the limits of human speech imitation, while *[IBM's AI](https://newsroom.ibm.com/2018-06-18-IBM-Debuts-Project-Debater-AI-System-That-Masters-Debate)* has impressively held its own in debates against humans—both examples showcasing the remarkable progress of AI.\n",
       "\n",
       "## AI: A Game Changer Across Industries\n",
       "\n",
       "The transformative potential of AI is being acknowledged and utilized by industry giants like Google, Apple, Microsoft, Amazon, IBM, and Facebook. For instance, Apple's latest iPhone models leverage AI to enhance the user experience, while Amazon's AI-powered Alexa Echo offers a new dimension to home automation. The influence of AI is also witnessed in sectors like healthcare—assisting in disease diagnosis and treatment, and logistics—improving supply chain and delivery processes.\n",
       "\n",
       "## The Future of AI: A Double-Edged Sword?\n",
       "\n",
       "As AI continues to evolve, it presents both opportunities and challenges. On the upside, AI is predicted to generate new jobs and enhance productivity. However, it also brings to light concerns over job displacement and privacy violations. For example, *[Microsoft's AI for accessibility](https://blogs.microsoft.com/accessibility/category/ai-for-accessibility/)* initiative empowers people with disabilities. Conversely, Facebook's use of AI to mitigate hate speech has sparked controversy over surveillance and censorship.\n",
       "\n",
       "In this ever-changing AI landscape, staying informed is paramount. Whether you're a tech enthusiast, business owner, student, or IT professional, understanding AI and its capabilities will better equip us to leverage its benefits and navigate its potential pitfalls. We welcome your thoughts on AI's influence on your life and encourage you to continue this conversation.\n",
       "\n",
       "_*Sources:_ [Statista](https://www.statista.com/statistics/607716/worldwide-artificial-intelligence-market-revenues/), [Google AI Blog](https://blog.google/technology/ai/), [IBM Newsroom](https://newsroom.ibm.com/), [Apple](https://www.apple.com/iphone/), [Amazon](https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/b?ie=UTF8&node=9818047011), [Microsoft AI](https://www.microsoft.com/en-us/ai/ai-for-accessibility), [Facebook AI](https://ai.facebook.com/), [TechCrunch](https://techcrunch.com/), [Wired](https://www.wired.com/), [The Verge](https://www.theverge.com/).*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3547a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cdf58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
