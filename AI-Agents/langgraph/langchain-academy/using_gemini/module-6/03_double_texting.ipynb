{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL8igeqQl-2U"
      },
      "source": [
        "# Double Texting\n",
        "\n",
        "Many times users might interact with your graph in unintended ways. For instance, a user may send one message and before the graph has finished running send a second message. More generally, users may invoke the graph a second time before the first run has finished. We call this “double texting”.\n",
        "\n",
        "Seamless handling of [double texting](https://langchain-ai.github.io/langgraph/concepts/double_texting/) is important for handling real-world usage scenarios, especially in chat applications.\n",
        "\n",
        "Users can send multiple messages in a row before the prior run(s) complete, and we want to ensure that we handle this gracefully.\n",
        "\n",
        "## Reject\n",
        "\n",
        "A simple approach is to [reject](https://langchain-ai.github.io/langgraph/cloud/how-tos/reject_concurrent/) any new runs until the current run completes.\n",
        "\n",
        "The guide covers the reject option for double texting, which rejects the new run of the graph by throwing an error and continues with the original run until completion. Below is a quick example of using the reject option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARk3ruMGl-2Y"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph_sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEc2ect5l-2Z"
      },
      "outputs": [],
      "source": [
        "from langgraph_sdk import get_client\n",
        "url_for_cli_deployment = \"http://localhost:8123\"\n",
        "client = get_client(url=url_for_cli_deployment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwayPDHil-2Z",
        "outputId": "eccab5d8-a255-473a-fd30-7a25df7fe52f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to start concurrent run Client error '409 Conflict' for url 'http://localhost:8123/threads/2b58630e-00fd-4c35-afad-a6b59e9b9104/runs'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409\n"
          ]
        }
      ],
      "source": [
        "import httpx\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Create a thread\n",
        "thread = await client.threads.create()\n",
        "\n",
        "# Create to dos\n",
        "user_input_1 = \"Add a ToDo to follow-up with DI Repairs.\"\n",
        "user_input_2 = \"Add a ToDo to mount dresser to the wall.\"\n",
        "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
        "graph_name = \"task_maistro\"\n",
        "\n",
        "run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
        "    config=config,\n",
        ")\n",
        "try:\n",
        "    await client.runs.create(\n",
        "        thread[\"thread_id\"],\n",
        "        graph_name,\n",
        "        input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
        "        config=config,\n",
        "        multitask_strategy=\"reject\",\n",
        "    )\n",
        "except httpx.HTTPStatusError as e:\n",
        "    print(\"Failed to start concurrent run\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aYBjq5yl-2b",
        "outputId": "edab40f3-0102-44f6-ef58-c9fba60abf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Add a ToDo to follow-up with DI Repairs.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_6xqHubCPNufS0bg4tbUxC0FU)\n",
            " Call ID: call_6xqHubCPNufS0bg4tbUxC0FU\n",
            "  Args:\n",
            "    update_type: todo\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New ToDo created:\n",
            "Content: {'task': 'Follow-up with DI Repairs', 'time_to_complete': 30, 'deadline': None, 'solutions': ['Call DI Repairs customer service', 'Email DI Repairs support', 'Check DI Repairs website for updates'], 'status': 'not started'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've added a task to follow-up with DI Repairs to your ToDo list. If there's anything else you need, feel free to let me know!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "\n",
        "# Wait until the original run completes\n",
        "await client.runs.join(thread[\"thread_id\"], run[\"run_id\"])\n",
        "\n",
        "# Get the state of the thread\n",
        "state = await client.threads.get_state(thread[\"thread_id\"])\n",
        "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vagVOPmHl-2b"
      },
      "source": [
        "## Enqueue\n",
        "\n",
        "We can use [enqueue](https://langchain-ai.github.io/langgraph/cloud/how-tos/enqueue_concurrent/https://langchain-ai.github.io/langgraph/cloud/how-tos/enqueue_concurrent/) any new runs until the current run completes.\n",
        "\n",
        "The guide covers the enqueue option for double texting, which adds the interruptions to a queue and executes them in the order they are received by the client. Below is a quick example of using the enqueue option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pThgDMdl-2c",
        "outputId": "8525cb99-bf53-44b3-e468-2e56925c33ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Send Erik his t-shirt gift this weekend.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_svTeXPmWGTLY8aQ8EifjwHAa)\n",
            " Call ID: call_svTeXPmWGTLY8aQ8EifjwHAa\n",
            "  Args:\n",
            "    update_type: todo\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New ToDo created:\n",
            "Content: {'task': 'Send Erik his t-shirt gift', 'time_to_complete': 30, 'deadline': '2024-11-19T23:59:00', 'solutions': ['Wrap the t-shirt', \"Get Erik's address\", 'Visit the post office', 'Choose a delivery service'], 'status': 'not started'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've updated your ToDo list to send Erik his t-shirt gift this weekend. If there's anything else you need, feel free to let me know!\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Get cash and pay nanny for 2 weeks. Do this by Friday.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_Cq0Tfn6yqccHH8n0DOucz5OQ)\n",
            " Call ID: call_Cq0Tfn6yqccHH8n0DOucz5OQ\n",
            "  Args:\n",
            "    update_type: todo\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New ToDo created:\n",
            "Content: {'task': 'Get cash and pay nanny for 2 weeks', 'time_to_complete': 15, 'deadline': '2024-11-17T23:59:00', 'solutions': ['Visit the ATM', 'Calculate the total amount for 2 weeks', 'Hand over the cash to the nanny'], 'status': 'not started'}\n",
            "\n",
            "Document af1fe011-f3c5-4c1c-b98b-181869bc2944 updated:\n",
            "Plan: Update the deadline for sending Erik his t-shirt gift to this weekend, which is by 2024-11-17.\n",
            "Added content: 2024-11-17T23:59:00\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've updated your ToDo list to ensure you get cash and pay the nanny for 2 weeks by Friday. Let me know if there's anything else you need!\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "\n",
        "# Create new ToDos\n",
        "user_input_1 = \"Send Erik his t-shirt gift this weekend.\"\n",
        "user_input_2 = \"Get cash and pay nanny for 2 weeks. Do this by Friday.\"\n",
        "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
        "graph_name = \"task_maistro\"\n",
        "\n",
        "first_run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "second_run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
        "    config=config,\n",
        "    multitask_strategy=\"enqueue\",\n",
        ")\n",
        "\n",
        "# Wait until the second run completes\n",
        "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
        "\n",
        "# Get the state of the thread\n",
        "state = await client.threads.get_state(thread[\"thread_id\"])\n",
        "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol4-JyeAl-2c"
      },
      "source": [
        "## Interrupt\n",
        "\n",
        "We can use [interrupt](https://langchain-ai.github.io/langgraph/cloud/how-tos/interrupt_concurrent/) to interrupt the current run, but save all the work that has been done so far up to that point.\n",
        "\n",
        "The guide covers the interrupt option for double texting, which interrupts the prior run of the graph and starts a new one with the double-text. This option does not delete the first run, but rather keeps it in the database but sets its status to interrupted. Below is a quick example of using the interrupt option.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t74eXnD8l-2c",
        "outputId": "4289aa9a-5c7c-45b3-caa6-f0347ca9d09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Give me a summary of my ToDos due tomrrow.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Never mind, create a ToDo to Order Ham for Thanksgiving by next Friday.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  UpdateMemory (call_Rk80tTSJzik2oY44tyUWk8FM)\n",
            " Call ID: call_Rk80tTSJzik2oY44tyUWk8FM\n",
            "  Args:\n",
            "    update_type: todo\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "New ToDo created:\n",
            "Content: {'task': 'Order Ham for Thanksgiving', 'time_to_complete': 30, 'deadline': '2024-11-22T23:59:59', 'solutions': ['Check local grocery stores for availability', 'Order online from a specialty meat provider', 'Visit a local butcher shop'], 'status': 'not started'}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I've added the task \"Order Ham for Thanksgiving\" to your ToDo list with a deadline of next Friday. If you need any more help, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "\n",
        "# Create new ToDos\n",
        "user_input_1 = \"Give me a summary of my ToDos due tomrrow.\"\n",
        "user_input_2 = \"Never mind, create a ToDo to Order Ham for Thanksgiving by next Friday.\"\n",
        "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
        "graph_name = \"task_maistro\"\n",
        "\n",
        "interrupted_run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "# Wait for some of run 1 to complete so that we can see it in the thread\n",
        "await asyncio.sleep(1)\n",
        "\n",
        "second_run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
        "    config=config,\n",
        "    multitask_strategy=\"interrupt\",\n",
        ")\n",
        "\n",
        "# Wait until the second run completes\n",
        "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
        "\n",
        "# Get the state of the thread\n",
        "state = await client.threads.get_state(thread[\"thread_id\"])\n",
        "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP86MVHnl-2d"
      },
      "source": [
        "We can see the initial run is saved, and has status `interrupted`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN-NpzYGl-2d",
        "outputId": "031985da-c6a9-4dd3-c1cb-b27428fe66af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "interrupted\n"
          ]
        }
      ],
      "source": [
        "# Confirm that the first run was interrupted\n",
        "print((await client.runs.get(thread[\"thread_id\"], interrupted_run[\"run_id\"]))[\"status\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awzkp0CEl-2d"
      },
      "source": [
        "## Rollback\n",
        "\n",
        "We can use [rollback](https://langchain-ai.github.io/langgraph/cloud/how-tos/rollback_concurrent/) to interrupt the prior run of the graph, delete it, and start a new run with the double-texted input.\n",
        "\n",
        "The guide covers the rollback option for double texting, which interrupts the prior run of the graph and starts a new one with the double-text. This option is very similar to the interrupt option, but in this case the first run is completely deleted from the database and cannot be restarted. Below is a quick example of using the rollback option.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_myRy7Iol-2d",
        "outputId": "36325039-12b9-411e-8959-73b707be6764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Actually, add a ToDo to drop by Yoga in person on Sunday.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "It looks like the task \"Drop by Yoga in person\" is already on your ToDo list with a deadline of November 19, 2024. Would you like me to update the deadline to the upcoming Sunday instead?\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "\n",
        "# Create new ToDos\n",
        "user_input_1 = \"Add a ToDo to call to make appointment at Yoga.\"\n",
        "user_input_2 = \"Actually, add a ToDo to drop by Yoga in person on Sunday.\"\n",
        "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
        "graph_name = \"task_maistro\"\n",
        "\n",
        "rolled_back_run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "second_run = await client.runs.create(\n",
        "    thread[\"thread_id\"],\n",
        "    graph_name,\n",
        "    input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
        "    config=config,\n",
        "    multitask_strategy=\"rollback\",\n",
        ")\n",
        "\n",
        "# Wait until the second run completes\n",
        "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
        "\n",
        "# Get the state of the thread\n",
        "state = await client.threads.get_state(thread[\"thread_id\"])\n",
        "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPtWaN7ml-2d"
      },
      "source": [
        "The initial run was deleted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apihOhBEl-2e",
        "outputId": "8f692491-5657-4c7f-c329-c74f62438348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original run was correctly deleted\n"
          ]
        }
      ],
      "source": [
        "# Confirm that the original run was deleted\n",
        "try:\n",
        "    await client.runs.get(thread[\"thread_id\"], rolled_back_run[\"run_id\"])\n",
        "except httpx.HTTPStatusError as _:\n",
        "    print(\"Original run was correctly deleted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzHvk2y6l-2e"
      },
      "source": [
        "### Summary\n",
        "\n",
        "We can see [all the methods summarized](https://langchain-ai.github.io/langgraph/concepts/double_texting/):\n",
        "\n",
        "![Screenshot 2024-11-15 at 12.13.18 PM.png](attachment:ff0af98b-71b1-497a-9c0e-b3519662fd2c.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}